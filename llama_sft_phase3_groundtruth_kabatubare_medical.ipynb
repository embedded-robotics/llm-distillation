{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLaMA Supervised Fine-Tuning on Ground Truth Answers\n",
    "\n",
    "This document will take the ground truth answers of the Kababutare Medical Dataset and then fine-tune the LLaMA Model on those answers.\n",
    "\n",
    "The purpose of this exercise is to test whether the LLaMA fine-tuning on ground truth answers will improve the performance on the open-ended question/answering related to healthcare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/mn27889/miniconda3/envs/mental-health-agents/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported, train_on_responses_only\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the Question and Answer Pairs from Training Dataset Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_list = []\n",
    "ans_list = []\n",
    "\n",
    "with open('phase2_data_kabatubare/train_kabatubare.jsonl', 'rb') as file: #only reading the training dataset\n",
    "    for line in file:\n",
    "        json_object = json.loads(line)\n",
    "        ques_list.append(json_object['question'])\n",
    "        ans_list.append(json_object['answer']) #getting GPT Responses from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have a small dull ache in my left testicle a...</td>\n",
       "      <td>just give it a rest my friend. it is not likel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i've heard conflicting opinions. 7 weeks of pr...</td>\n",
       "      <td>hi the best thing is to live your life as norm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my friend slept over that had fever blisters. ...</td>\n",
       "      <td>hi found you this little piece of info. oral h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what are some common food triggers for migraines?</td>\n",
       "      <td>you can use information from your diary and tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>why does grey hair itch so much? . why does my...</td>\n",
       "      <td>hair doesn't itch. scalps will itch. there are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18744</th>\n",
       "      <td>how to make money online? . a brand new approa...</td>\n",
       "      <td>please do not post advertising on webmd answer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18745</th>\n",
       "      <td>what can i eat with the stomach flu? . i can't...</td>\n",
       "      <td>the best foods to eat while feeling nausea are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18746</th>\n",
       "      <td>what exams and tests help doctors to evaluate ...</td>\n",
       "      <td>doctors can often easily recognize ringworm wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18747</th>\n",
       "      <td>could i be pregnant?</td>\n",
       "      <td>the only way to know for sure you're pregnant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18748</th>\n",
       "      <td>if i have an anal fissure should i see a gastr...</td>\n",
       "      <td>that is really up to you. most anal fissures h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18749 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0      i have a small dull ache in my left testicle a...   \n",
       "1      i've heard conflicting opinions. 7 weeks of pr...   \n",
       "2      my friend slept over that had fever blisters. ...   \n",
       "3      what are some common food triggers for migraines?   \n",
       "4      why does grey hair itch so much? . why does my...   \n",
       "...                                                  ...   \n",
       "18744  how to make money online? . a brand new approa...   \n",
       "18745  what can i eat with the stomach flu? . i can't...   \n",
       "18746  what exams and tests help doctors to evaluate ...   \n",
       "18747                               could i be pregnant?   \n",
       "18748  if i have an anal fissure should i see a gastr...   \n",
       "\n",
       "                                                  answer  \n",
       "0      just give it a rest my friend. it is not likel...  \n",
       "1      hi the best thing is to live your life as norm...  \n",
       "2      hi found you this little piece of info. oral h...  \n",
       "3      you can use information from your diary and tr...  \n",
       "4      hair doesn't itch. scalps will itch. there are...  \n",
       "...                                                  ...  \n",
       "18744  please do not post advertising on webmd answer...  \n",
       "18745  the best foods to eat while feeling nausea are...  \n",
       "18746  doctors can often easily recognize ringworm wh...  \n",
       "18747  the only way to know for sure you're pregnant ...  \n",
       "18748  that is really up to you. most anal fissures h...  \n",
       "\n",
       "[18749 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth_data = pd.DataFrame({'question': ques_list, 'answer': ans_list})\n",
    "groundtruth_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the HuggingFace Dataset from Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 16874\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 1875\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(groundtruth_data)\n",
    "dataset = dataset.train_test_split(test_size=0.1) #dividing the training dataset into further train:validation dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.2.\n",
      "   \\\\   /|    NVIDIA RTX A6000. Num GPUs = 1. Max memory: 47.413 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.4.1+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.0.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct\",\n",
    "    max_seq_length = 2048,\n",
    "    load_in_4bit = False, # 4 bit quantization to reduce memory\n",
    "    load_in_8bit = True, # [NEW!] A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
    "    dtype=None, #None for auto-detection. Can be torch.bfloat16 or torch.float16 (will be automatically detected)\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the PEFT settings for the model\n",
    "\n",
    "https://huggingface.co/blog/damjan-k/rslora\\\n",
    "https://medium.com/@fartypantsham/what-rank-r-and-alpha-to-use-in-lora-in-llm-1b4f025fd133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 64, #max_full_rank=64 by default in FastLanguageModel\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 64, #scaling_factor = lora_alpha/r. If we select lora_alpha = 2 * r then it will multiply the adapter weights by 2 which can be un-ncessary\n",
    "    lora_dropout = 0.1,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    use_rslora = True,\n",
    "    loftq_config = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forming the chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply the chat template\n",
    "def format_chat_template(example):\n",
    "        \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a medical knowledge assistant trained to provide information and guidance on various health-related topics.\"},\n",
    "        {\"role\": \"user\", \"content\": example['question']},\n",
    "        {\"role\": \"assistant\", \"content\": example['answer']}\n",
    "    ]\n",
    "    \n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "    return {\"text\": prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16874/16874 [00:02<00:00, 6444.93 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [00:00<00:00, 6524.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_formatted = dataset.map(format_chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 07 Apr 2025\n",
      "\n",
      "You are a medical knowledge assistant trained to provide information and guidance on various health-related topics.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "i am currently taking 1mg of klonopin twice a day & i would like to increase my 20mg prozac to twice a day. is this safe<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "the short answer is: no it's not safe. no one should adjust their doses of prescription drugs without consulting a doctor. in your case you're taking one anti-anxiety medication and one antidepressant. you should not adjust the dosage of either of these medications without checking with your doctor first. if you feel the prozac (fluoxetine) is not helping your depression i'd suggest you discuss your symptoms with your doctor. he or she may want to change your antidepressant medication to something else. there are plenty of antidepressants to choose from. i wish you all the best!<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(dataset_formatted['train']['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing the TRL SFTTrainer and related Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16874/16874 [00:06<00:00, 2566.30 examples/s]\n",
      "Unsloth: Tokenizing [\"text\"] (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [00:01<00:00, 1141.32 examples/s]\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "peft_model_path = \"./llama32-sft-peft-kabatubare-phase3-groundtruth\" #use for LoRA based fine-tuning\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=peft_model_path,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        # gradient_accumulation_steps=4,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=50,\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=50,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=1000,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 1,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "        seed = 42,\n",
    "        report_to = \"none\",\n",
    "    )\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset=dataset_formatted[\"train\"],\n",
    "    eval_dataset=dataset_formatted[\"test\"],\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = 2048,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer), #only use when using train_on_responses_only()\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 16874\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 07 Apr 2025\n",
      "\n",
      "You are a medical knowledge assistant trained to provide information and guidance on various health-related topics.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "i am currently taking 1mg of klonopin twice a day & i would like to increase my 20mg prozac to twice a day. is this safe<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "the short answer is: no it's not safe. no one should adjust their doses of prescription drugs without consulting a doctor. in your case you're taking one anti-anxiety medication and one antidepressant. you should not adjust the dosage of either of these medications without checking with your doctor first. if you feel the prozac (fluoxetine) is not helping your depression i'd suggest you discuss your symptoms with your doctor. he or she may want to change your antidepressant medication to something else. there are plenty of antidepressants to choose from. i wish you all the best!<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(trainer.train_dataset['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only Focus on the `Response Part` for the generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16874/16874 [00:02<00:00, 7832.24 examples/s] \n",
      "Map (num_proc=64): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [00:01<00:00, 1235.05 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 16874\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " 1820,\n",
       " 2875,\n",
       " 4320,\n",
       " 374,\n",
       " 25,\n",
       " 912,\n",
       " 433,\n",
       " 596,\n",
       " 539,\n",
       " 6220,\n",
       " 13,\n",
       " 912,\n",
       " 832,\n",
       " 1288,\n",
       " 7652,\n",
       " 872,\n",
       " 35130,\n",
       " 315,\n",
       " 22866,\n",
       " 11217,\n",
       " 2085,\n",
       " 31831,\n",
       " 264,\n",
       " 10896,\n",
       " 13,\n",
       " 304,\n",
       " 701,\n",
       " 1162,\n",
       " 499,\n",
       " 2351,\n",
       " 4737,\n",
       " 832,\n",
       " 7294,\n",
       " 19415,\n",
       " 16708,\n",
       " 24099,\n",
       " 323,\n",
       " 832,\n",
       " 65211,\n",
       " 519,\n",
       " 13,\n",
       " 499,\n",
       " 1288,\n",
       " 539,\n",
       " 7652,\n",
       " 279,\n",
       " 47040,\n",
       " 315,\n",
       " 3060,\n",
       " 315,\n",
       " 1521,\n",
       " 31010,\n",
       " 2085,\n",
       " 13598,\n",
       " 449,\n",
       " 701,\n",
       " 10896,\n",
       " 1176,\n",
       " 13,\n",
       " 422,\n",
       " 499,\n",
       " 2733,\n",
       " 279,\n",
       " 463,\n",
       " 96726,\n",
       " 320,\n",
       " 27256,\n",
       " 91703,\n",
       " 8,\n",
       " 374,\n",
       " 539,\n",
       " 10695,\n",
       " 701,\n",
       " 18710,\n",
       " 602,\n",
       " 4265,\n",
       " 4284,\n",
       " 499,\n",
       " 4358,\n",
       " 701,\n",
       " 13803,\n",
       " 449,\n",
       " 701,\n",
       " 10896,\n",
       " 13,\n",
       " 568,\n",
       " 477,\n",
       " 1364,\n",
       " 1253,\n",
       " 1390,\n",
       " 311,\n",
       " 2349,\n",
       " 701,\n",
       " 65211,\n",
       " 519,\n",
       " 24099,\n",
       " 311,\n",
       " 2555,\n",
       " 775,\n",
       " 13,\n",
       " 1070,\n",
       " 527,\n",
       " 11510,\n",
       " 315,\n",
       " 65211,\n",
       " 1821,\n",
       " 311,\n",
       " 5268,\n",
       " 505,\n",
       " 13,\n",
       " 602,\n",
       " 6562,\n",
       " 499,\n",
       " 682,\n",
       " 279,\n",
       " 1888,\n",
       " 0,\n",
       " 128009]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The labels are created which only contain response. Left Padding is implemented and all the padding tokens are given a score of -100 to avoid loss calculation for pad_tokens\n",
    "trainer.train_dataset['labels'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 16,874 | Num Epochs = 1 | Total steps = 2,110\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 1 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 97,255,424/3,310,005,248 (2.94% trained)\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model and tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just save the LoRA Adapters without merging with base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_path = \"./llama32-sft-peft-kabatubare-phase3-groundtruth\" #use for LoRA based fine-tuning\n",
    "\n",
    "# Or run the two below statements\n",
    "model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_path = \"./llama32-sft-peft-kabatubare-phase3-groundtruth\" #use for LoRA based fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.2.\n",
      "   \\\\   /|    NVIDIA RTX A6000. Num GPUs = 1. Max memory: 47.413 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.4.1+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.0.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.19 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = peft_model_path,\n",
    "    max_seq_length = 2048,\n",
    "    load_in_4bit = False, # 4 bit quantization to reduce memory\n",
    "    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
    "    dtype=None, #None for auto-detection. Can be torch.bfloat16 or torch.float16 (will be automatically detected)\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'gpt_response_base'],\n",
       "    num_rows: 1875\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can you identify this strange blister? . what is a small blister-like flat bubble on my shoulder that causes no pain and no itchiness? it may have gone down a bit during the three weeks it has been there. no spreading and no additional blisters found. first i have ever noticed in my 57 years.\n",
      "I'm not a doctor, but I can provide some general information. A small blister-like flat bubble on the skin that is not painful or itchy could be due to several reasons. Here are a few possibilities:\n",
      "\n",
      "1. **Cyst**: A sebaceous cyst is a common benign growth that can feel like a small bump or bubble under the skin. They are usually painless and may change in size.\n",
      "\n",
      "2. **Lipoma**: This is a benign tumor made of fat tissue. It's typically soft, movable, and painless.\n",
      "\n",
      "3. **Insect bite or sting**: Sometimes, insect bites can create small, raised bumps that may resemble blisters, but they are usually itchy.\n",
      "\n",
      "4. **Folliculitis**: This is an inflammation of hair follicles that can create small bumps, often in areas where hair is present.\n",
      "\n",
      "5. **Contact dermatitis**: This could result from a reaction to something that has come into contact with your skin, but it often comes with some degree of irritation or itchiness.\n",
      "\n",
      "Given that it has been present for three weeks and has not changed significantly, it may be a benign condition. However, it's important to have any new or changing skin lesions evaluated by a healthcare professional for an accurate diagnosis and appropriate treatment if necessary.\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# for idx in range(1,50):\n",
    "\n",
    "idx = 1\n",
    "\n",
    "print(dataset['test']['question'][idx])\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a medical knowledge assistant trained to provide information and guidance on various health-related topics.\"},\n",
    "            {\"role\": \"user\", \"content\": dataset['test']['question'][idx]}]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(model.device)\n",
    "temp_resp = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=2048, num_return_sequences=1)\n",
    "\n",
    "resp = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "resp = resp[len(temp_resp):] #getting only the response part (i.e., assistant)\n",
    "\n",
    "print(resp)\n",
    "print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mental-health-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
