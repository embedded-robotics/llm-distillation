{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLaMA Supervised Fine-Tuning\n",
    "\n",
    "This document will take the answers of GPT-4o on the Kababutare Medical Dataset and then fine-tune the LLaMA Model on those answers.\n",
    "\n",
    "The purpose of this exercise is to test whether the LLaMA fine-tuning is able to distill the knowledge of GPT-4o and improve the performance on the open-ended question/answering related to healthcare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/mn27889/miniconda3/envs/mental-health-agents/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import Dataset\n",
    "from tqdm  import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the Question and Answer Pairs from Phase 1 of GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>gpt_response_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my 5 1/2-year-old son displays adhd symptoms f...</td>\n",
       "      <td>Itâ€™s important to remember that only a qualifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my son has add and mild autism. he has been su...</td>\n",
       "      <td>Weight management can be a concern for childre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my son is 13 and is depressed. he has been tak...</td>\n",
       "      <td>I'm really sorry to hear that your son is feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my 17-year-old has stopped taking concerta aft...</td>\n",
       "      <td>When a person, especially a teenager, stops ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been taking respa-ar for allergies. i can...</td>\n",
       "      <td>Resp-A-R is a combination medication commonly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23432</th>\n",
       "      <td>how can accidental of acetaminophen overdose b...</td>\n",
       "      <td>Accidental acetaminophen overdose is a signifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23433</th>\n",
       "      <td>what should i do if i take an overdose of maxalt?</td>\n",
       "      <td>If you suspect that you have taken an overdose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23434</th>\n",
       "      <td>what do i do in case of an overdose of relpax?</td>\n",
       "      <td>If you suspect an overdose of Relpax (eletript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23435</th>\n",
       "      <td>is overdose with acetaminophen usually acciden...</td>\n",
       "      <td>Overdoses of acetaminophen (also known as para...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23436</th>\n",
       "      <td>how does an overdose of acetaminophen cause li...</td>\n",
       "      <td>Acetaminophen (also known as paracetamol) is a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23437 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0      my 5 1/2-year-old son displays adhd symptoms f...   \n",
       "1      my son has add and mild autism. he has been su...   \n",
       "2      my son is 13 and is depressed. he has been tak...   \n",
       "3      my 17-year-old has stopped taking concerta aft...   \n",
       "4      i've been taking respa-ar for allergies. i can...   \n",
       "...                                                  ...   \n",
       "23432  how can accidental of acetaminophen overdose b...   \n",
       "23433  what should i do if i take an overdose of maxalt?   \n",
       "23434     what do i do in case of an overdose of relpax?   \n",
       "23435  is overdose with acetaminophen usually acciden...   \n",
       "23436  how does an overdose of acetaminophen cause li...   \n",
       "\n",
       "                                       gpt_response_base  \n",
       "0      Itâ€™s important to remember that only a qualifi...  \n",
       "1      Weight management can be a concern for childre...  \n",
       "2      I'm really sorry to hear that your son is feel...  \n",
       "3      When a person, especially a teenager, stops ta...  \n",
       "4      Resp-A-R is a combination medication commonly ...  \n",
       "...                                                  ...  \n",
       "23432  Accidental acetaminophen overdose is a signifi...  \n",
       "23433  If you suspect that you have taken an overdose...  \n",
       "23434  If you suspect an overdose of Relpax (eletript...  \n",
       "23435  Overdoses of acetaminophen (also known as para...  \n",
       "23436  Acetaminophen (also known as paracetamol) is a...  \n",
       "\n",
       "[23437 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_inf_data_phase1 = pd.DataFrame()\n",
    "ques_list = []\n",
    "gpt_resp_list = []\n",
    "\n",
    "with open('phase1_kabatubare_medical/kabatubare_medical_gpt4omini_qa_pairs.jsonl', 'rb') as file:\n",
    "    for line in file:\n",
    "        json_object = json.loads(line)\n",
    "        ques_list.append(json_object['Question'])\n",
    "        gpt_resp_list.append(json_object['Answer'])\n",
    "\n",
    "gpt_inf_data_phase1['question'] = ques_list\n",
    "gpt_inf_data_phase1['gpt_response_base'] = gpt_resp_list\n",
    "gpt_inf_data_phase1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the HuggingFace Dataset from Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'gpt_response'],\n",
       "        num_rows: 21093\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'gpt_response'],\n",
       "        num_rows: 2344\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(gpt_inf_data_phase1)\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_model_path = \"./llama32-sft-full-kabatubare\"\n",
    "peft_model_path = \"./llama32-sft-peft-kabatubare\" #use for LoRA based fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.2.\n",
      "   \\\\   /|    NVIDIA RTX A6000. Num GPUs = 1. Max memory: 47.413 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.4.1+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.0.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.19 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = peft_model_path,\n",
    "    max_seq_length = 4096,\n",
    "    load_in_4bit = False, # 4 bit quantization to reduce memory\n",
    "    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
    "    dtype=None, #None for auto-detection. Can be torch.bfloat16 or torch.float16 (will be automatically detected)\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing sample-by-sample inference. (Batch Inference doesn't work well for fine-tuned model adapters as responses like `P P P P` are being produced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama_response_ft(question_input: str):\n",
    "    \n",
    "    llama_input = [{\"role\": \"system\", \"content\": \"You are a medical knowledge assistant trained to provide information and guidance on various health-related topics.\"},\n",
    "                    {\"role\": \"user\", \"content\": question_input}]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(llama_input, tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "    inputs = tokenizer(prompt, padding=True, truncation=True, return_tensors=\"pt\").to(model.device)\n",
    "    temp_resp = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=4096,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "\n",
    "    resp = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    resp = resp[len(temp_resp):] #getting only the response part (i.e., assistant)\n",
    "    \n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Unsloth Fast Inference\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "llama_responses_ft = []\n",
    "for index, row in tqdm(gpt_inf_data_phase1.iterrows(), total=len(gpt_inf_data_phase1)):\n",
    "    question_input = row['gpt_response']\n",
    "    llama_resp = get_llama_response_ft(question_input)\n",
    "    llama_responses_ft.append(llama_resp)\n",
    "\n",
    "with open('phase2_kabatubare_medical/llama_responses_ft.pkl', 'wb') as file:\n",
    "    pickle.dump(llama_responses_ft, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('phase2_kabatubare_medical/llama_responses_ft.pkl', 'rb') as file:\n",
    "    llama_responses_ft = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mental-health-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
